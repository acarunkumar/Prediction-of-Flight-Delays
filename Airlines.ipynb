{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loadning required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"air.csv\")\n",
    "pd.set_option('display.max_columns', None)#to view the all 45 columns.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Name Description:\n",
    "\n",
    "FL_DATE: Date of the flight, mm/dd/yyyy\n",
    "\n",
    "OP_CARRIER: Airline Identifier\n",
    "\n",
    "OP_CARRIER_FL_NUM: Flight Number\n",
    "\n",
    "ORIGIN: Starting Airport Code\n",
    "\n",
    "DEST: Destination Airport Code\n",
    "\n",
    "CRS_DEP_TIME: Planned Departure Time\n",
    "\n",
    "DEP_TIME: Actual Departure Time\n",
    "\n",
    "DEP_DELAY: Total Delay on Departure in minutes\n",
    "\n",
    "TAXI_OUT: The time duration elapsed between departure from the origin airport gate and wheels off\n",
    "\n",
    "WHEELS_OFF: The time point that the aircraft's wheels leave the ground\n",
    "\n",
    "WHEELS_ON: The time point that the aircraft's wheels touch on the ground\n",
    "\n",
    "TAXI_IN: The time duration elapsed between wheels-on and gate arrival at the destination airport\n",
    "\n",
    "CRS_ARR_TIME: Planned arrival time\n",
    "\n",
    "ARR_TIME: Actual Arrival Time\n",
    "\n",
    "ARR_DELAY: Total Delay on Arrival in minutes\n",
    "\n",
    "CANCELLED: Flight Cancelled (1 = cancelled)\n",
    "\n",
    "CANCELLATION_CODE: Reason for Cancellation of flight: A - Airline/Carrier; B - Weather; C - National                    Air System; D - Security\n",
    "\n",
    "DIVERTED: Aircraft landed on airport that out of schedule\n",
    "\n",
    "CRS_ELAPSED_TIM: Planned time amount needed for the flight trip\n",
    "\n",
    "ACTUAL_ELAPSED_TIME: AIR_TIME+TAXI_IN+TAXI_OUT\n",
    "\n",
    "AIR_TIME: The time duration between wheels_off and wheels_on time\n",
    "\n",
    "DISTANCE: Distance between two airports\n",
    "\n",
    "CARRIER_DELAY: Delay caused by the airline in minutes\n",
    "\n",
    "WEATHER_DELAY: Delay caused by weather\n",
    "\n",
    "NAS_DELAY: Delay caused by air system\n",
    "\n",
    "SECURITY_DELAY: Delay caused by security\n",
    "\n",
    "LATE_AIRCRAFT_DELAY: Delay caused by security\n",
    "\n",
    "Unnamed: 44 - Useless column(100% NULL Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape# we have totally 448620 row/observations and 45 columns/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()#to check the data types and null values if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()#to check the total missing values in each columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()#to summarize the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.YEAR.unique()# Let's take the first column \"YEAR\" it has only 1987 for all 448620 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MONTH.unique()#In second column only from month of Octomber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DAY_OF_MONTH.unique()# in third column shows all day of october month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DAY_OF_WEEK.unique()#in fourth column 1-Mon, 2-Tue, 3-Wed, 4-Thu, 5-Fri, 6-Sat, 7-Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.FL_DATE.unique()#in fifth column it has only the date of Oct-1987."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION: 01\n",
    "\n",
    " As per the above observations we come to know that our dataset has a details of airways for the month of Octomber in 1987.\n",
    " \n",
    " Since we have the \"FL_DATE\" column we can remove the first 4 columns as \"YEAR\", \"MONTH\", \"DAY_OF_MONTH\", \"DAY_OF_WEEK\" from our dataset \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove the 4 columns\n",
    "\n",
    "df.drop(['YEAR','MONTH','DAY_OF_MONTH','DAY_OF_WEEK'], axis = 1,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # after removed the 4 columns we reduced our columns from 45 to 41. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # after FL_DATE we can explore UNIQUE_CARRIER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines=df.UNIQUE_CARRIER.unique() #Airline codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(airlines) #so totally we have 14 airlines details in the month of Octomber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines# airlines are code are gathered from wiki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airline Abbreviation:\n",
    "\n",
    "AA - American Airlines\n",
    "\n",
    "US - Unisted State Airways\n",
    "\n",
    "AS - Alska Airlines\n",
    "\n",
    "CO - Continental Airlines\n",
    "\n",
    "DL - Delta Airlines\n",
    "\n",
    "EA - Easter Airlines\n",
    "\n",
    "HP - Hawaiian Pacific Airlines\n",
    "\n",
    "NW - Northwest Airlines\n",
    "\n",
    "PA - Pan American Airways\n",
    "\n",
    "PI - Piedmont Airlines\n",
    "\n",
    "PS - Ukraine International\n",
    "\n",
    "TW - Twan Air\n",
    "\n",
    "UA - United Airlines\n",
    "\n",
    "WN - Southwest Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after UNIQUE_CARRIER column we can see a empty column name \"TAIL_NUM\" so we remove it since its \n",
    "#totally empty.\n",
    "\n",
    "df.drop(['TAIL_NUM'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now our third column is FL_NUM:\n",
    "\n",
    "df.FL_NUM.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl=df.groupby('FL_NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no any relationship between anyothere columns lets drop \"FL_NUM\".\n",
    "\n",
    "df.drop(['FL_NUM'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isnull().any()] # to find the column names for the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate the percentage of the missing values:\n",
    "\n",
    "missing_df = df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['filling factor (%)']=(df.shape[0]-missing_df['missing values'])/df.shape[0]*100\n",
    "missing_df.sort_values('filling factor (%)').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION: 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per above, Now we can see that the missing values are >99% since its not gonna affect our model at all. However we can also see that 12 columns are totally 0% i.e., it is totally zero so lets remove the 12 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 44','WHEELS_ON','CANCELLATION_CODE','TAXI_IN','LATE_AIRCRAFT_DELAY','TAXI_OUT','WHEELS_OFF','AIR_TIME','CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape# now our dataset has only 28 variables from 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION: 03\n",
    "\n",
    " As you can see in the column nameS \"FLIGHTS\" and \"CANCELLED\" its shows mostly it has some nan value so lets explore on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.FLIGHTS.unique()#for all 448620 it has onle \"1\" so it doesn't mean anything lets drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['FLIGHTS'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape#now we reduced the variable from 28 to 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CANCELLED.unique()#1-cancelled, 0-non_cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can=df[(df['CANCELLED'])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(can)#total cancelled flights we have 3001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION:04\n",
    "\n",
    " 1.Since the flight was cancelled(Not opereated) under column names DEP_TIME, DEP_DELAY, DEP_DELAY_NEW, DEP_DEL15, DEP_DELAY_GROUP, ARR_TIME\tARR_DELAY\tARR_DELAY_NEW\tARR_DEL15\tARR_DELAY_GROUP and ACTUAL_ELAPSED_TIME\tare obviously we will get \"NAN\" values.\n",
    " \n",
    " 2.As you can see the  column name DEP_DELAY_NEW, DEP_DELAY_GROUP, ARR_DELAY_NEW, ARR_DELAY_GROUP are not necessary so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ARR_DELAY_NEW','ARR_DELAY_GROUP','DEP_DELAY_NEW','DEP_DELAY_GROUP','DISTANCE_GROUP'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape#now again we reduced the variable from 27 to 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION:05\n",
    "\n",
    " Now we can see some clear correlations in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARRIVAL DELAYS BY DATE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('FL_DATE').ARR_DELAY.sum().plot.bar()\n",
    "plt.title('ARRIVAL DELAYS BY DATE')\n",
    "plt.ylabel('Hours')\n",
    "plt.xlabel('Month of the year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPARTURE DELAYS BY DATE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('FL_DATE').DEP_DELAY.sum().plot.bar()\n",
    "plt.title('DEPARTURE DELAYS BY DATE')\n",
    "plt.ylabel('Hours')\n",
    "plt.xlabel('Date of Departure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPARTURE DELAYS BY > 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('FL_DATE').DEP_DEL15.sum().plot.bar()\n",
    "plt.title('DEPARTURE DELAYS BY >15')\n",
    "plt.ylabel('Hours')\n",
    "plt.xlabel('Date of Departure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARRIVAL DELAYS BY > 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('FL_DATE').ARR_DEL15.sum().plot.bar()\n",
    "plt.title('ARRIVAL DELAYS BY >15')\n",
    "plt.ylabel('Hours')\n",
    "plt.xlabel('Date of Departure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELAYS BY AIRLINES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('UNIQUE_CARRIER').ARR_DELAY.sum().sort_values(ascending=False).plot.bar()\n",
    "plt.title('AIRWAYS DELAYS IN OCTOBER')\n",
    "plt.ylabel('Hours')\n",
    "plt.xlabel('Date of Departure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPARTURE DELAYS BY CITIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('ORIGIN').DEP_DELAY.sum().sort_values(ascending=False).plot.bar()\n",
    "plt.title('DEPARTURE DELAY BY CITIES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As per above plot we can get the clear picture so let's grab only top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dep_delay = df.groupby('ORIGIN').DEP_DELAY.sum().sort_values(ascending=False)\n",
    "city_dep_delay[:20].plot.bar()\n",
    "plt.title('DEPARTURE DELAY BY TOP 20 CITIES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION: 06\n",
    "\n",
    " As we can see in the above plots for the delay in Departure/Arrival mostly the maximum delays happened in the weekends.\n",
    "\n",
    "10-01-1987 - Thursday\n",
    "\n",
    "10-09-1987 - Friday\n",
    "\n",
    "10-16-1987 - Friday\n",
    "\n",
    "10-22-1987 - Thursday\n",
    "\n",
    "10-23-1987 - Friday\n",
    "\n",
    "10-25-1987 - Sunday\n",
    "\n",
    "10-28-1987 - Wednesday\n",
    "\n",
    "10-29-1987 - Thursday\n",
    "\n",
    "# OBSERVATIONS: 07\n",
    "\n",
    " As we can see in the above plots for the delay by airways mostly the maximum delays happened in the DL - Delta Airlines and the least delays in Pan America Airways. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To check the maximum delay by the date: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('FL_DATE')[['ARR_DELAY']].max().sort_values(by='ARR_DELAY',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To check the total number of airport :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of airports: {}\".format(len(df['ORIGIN'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To check the top 10 cities by departures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "axis = sns.countplot(x=df['ORIGIN'], data = df,order=df['ORIGIN'].value_counts().iloc[:10].index)\n",
    "axis.set_xticklabels(axis.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To check the top 10 airways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "axis = sns.countplot(x=df['UNIQUE_CARRIER'], data = df,order=df['UNIQUE_CARRIER'].value_counts().iloc[:10].index)\n",
    "axis.set_xticklabels(axis.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's drop the NA's in all rows to see the correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna()\n",
    "print(\"Shape of old dataset:\",df.shape)\n",
    "print(\"Shape of non-null dataset:\",df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = plt.subplots(figsize=(20,14))\n",
    "sns.heatmap(df1.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATIONS: 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. As we can there is high correlation between ARR_TIME and DEP_TIME, ACTUAL_ELAPSED_TIME and DISTANCE.\n",
    " 2. You can see the \"CANCELLED\" and \"DIVERTED\" columns are blanks since it has only \"0\" and \"1\" and also we don't need this column to predict our delayed flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping \"CANCELLED\" and \"DIVERTED\" columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.drop([\"CANCELLED\",\"DIVERTED\"],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()# now there is no any missing values lets begin to build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to change categorical variables into numerical one\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df1['FL_DATE']= le.fit_transform(df1['FL_DATE'])\n",
    "df1['UNIQUE_CARRIER']= le.fit_transform(df1['UNIQUE_CARRIER'])\n",
    "df1['ORIGIN']= le.fit_transform(df1['ORIGIN'])\n",
    "df1['ORIGIN_STATE_ABR']= le.fit_transform(df1['ORIGIN_STATE_ABR'])\n",
    "df1['DEST']= le.fit_transform(df1['DEST'])\n",
    "df1['DEST_STATE_ABR']= le.fit_transform(df1['DEST_STATE_ABR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split 'x' and 'y' from our dataset 'df1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df1['ARR_DELAY']#dependent variavle \"Y\"\n",
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1.drop('ARR_DELAY',axis = 1)\n",
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test dataset:\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets check the shape of the splitted datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train shape is:\",x_train.shape)\n",
    "print(\"x_test shape is:\",x_test.shape)\n",
    "print(\"y_train shape is:\",y_train.shape)\n",
    "print(\"y_test shape is:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc1=StandardScaler()\n",
    "x_train_sc=sc1.fit_transform(x_train)\n",
    "x_test_sc=sc1.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,LinearRegression,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "Las = Lasso()\n",
    "LinR = LinearRegression()\n",
    "Rid = Ridge()\n",
    "Rfc = RandomForestRegressor(random_state=2)\n",
    "Dtc = DecisionTreeRegressor(random_state = 2)\n",
    "\n",
    "for model, name in zip([Las,LinR,Rid,Dtc,Rfc],['Lasso','Linear Regression','Ridge','Random forest Regressor','Decision Tree Regressor']):\n",
    "    model1 = model.fit(x_train_sc,y_train)\n",
    "    Y_predict=model1.predict(x_test_sc)\n",
    "    print(name)\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y_test, Y_predict))  \n",
    "    print('Mean Squared Error:', mean_squared_error(y_test, Y_predict))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, Y_predict)))\n",
    "    print('R2 : ',r2_score(y_test, Y_predict))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in zip([Las,LinR,Rid,Dtc,Rfc], ['Lasso','Linear Regression','Ridge','Random forest Regressor','Decision Tree Regressor']):\n",
    "    model1 = model.fit(x_train_sc,y_train)\n",
    "    Y_predict=model1.predict(x_test_sc)\n",
    "    print(name)\n",
    "    plt.scatter(y_test, Y_predict)\n",
    "    plt.title(\"Model Analysis\")\n",
    "    plt.xlabel(\"Truth\")\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Actual': y_test, 'Predicted': Y_predict}).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
